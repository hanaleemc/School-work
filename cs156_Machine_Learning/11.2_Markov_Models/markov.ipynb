{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech recognition\n",
    "\n",
    "This week we will deal with a simplified form of speech recognition. The languages are artificial and have been generated using a combination of Markov models and hidden Markov models (HMMs). In real life things are much more messy! This artificial data makes for a better tutorial with cleaner results.\n",
    "\n",
    "There are two forms of the datasets available. In the first form, there are several audio files, which can be parsed into discrete phonemes. In the second form, the parsing has already been done for you, and you are presented with long sequences of symbols. It is worth listening to the audio yourself, and seeing if you can determine any differences between the “languages” or “speakers” by ear!\n",
    "\n",
    "\n",
    "If you want to process the audio dataset yourself, rather than using the parsed dataset, then it is advised to use: scipy.io.wavfile to read an audio file. All audio will be single channel (mono) and noiselessly generated from a small set of component sounds.\n",
    "\n",
    "\n",
    "1 - Language detection\n",
    "\n",
    "There are three languages: A, B, and C. Each language uses the same set of symbols: “A, o, e, t, p, g, and k. However, each language uses the symbols differently. In each of these languages we can model everything as P(next symbol | current symbol).\n",
    "\n",
    "There is training data available for each language. This consists of several files each generated by sampling from a Markov model. Using python, build a Markov model for each of the languages.\n",
    "Now use the Markov model and Bayes’ rule to classify the test cases. Write down how you used Bayes’ rule to get your classifier. Give the full posterior distribution for each test case.\n",
    "Audio dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/nglEdY/audio.zip\n",
    "\n",
    "Symbol dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/ryDvKV/symbol.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'symbol/*'\n",
    "# files = glob.glob(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = ['A', 'o', 'e', 't', 'p', 'g', 'k']\n",
    "LANGS = ('A', 'B', 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A = [f for f in glob.glob(path) if \"langA\" in f ]\n",
    "train_B = [f for f in glob.glob(path) if \"langB\" in f ]\n",
    "train_C = [f for f in glob.glob(path) if \"C\" in f ]\n",
    "test = [f for f in glob.glob(path) if \"test\" in f ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(CHARS)\n",
    "M = len(LANGS)\n",
    "\n",
    "# fit params (N*N matrix)\n",
    "trans_matrix_A = np.zeros ((N,N))\n",
    "probab_matrix_A = np.ones_like((N,N))\n",
    "\n",
    "trans_matrix_B = np.zeros ((N,N))\n",
    "probab_matrix_B = np.ones_like((N,N))\n",
    "\n",
    "trans_matrix_C = np.zeros ((N,N))\n",
    "probab_matrix_C = np.ones_like((N,N))\n",
    "\n",
    "#predict params\n",
    "prior = np.ones((M,)) / M # uniform prior row vector (M*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit funcs\n",
    "\n",
    "#Use seq to fit the prob matrix\n",
    "def fit_model(sequence, probab_matrix, trans_matrix, CHARS=CHARS):\n",
    "    #counts of transitions\n",
    "    for first, second in zip(sequence, sequence[1:]):\n",
    "        trans_matrix[CHARS.index(first), CHARS.index(second)] += 1 \n",
    "#     print (trans_matrix)\n",
    "#     print (np.sum(trans_matrix, axis=1)) \n",
    "    \n",
    "    #normlize\n",
    "#     row_sums = trans_matrix.sum(axis=1)\n",
    "#     probab_matrix = trans_matrix / row_sums[:, np.newaxis]\n",
    "    return (trans_matrix / np.sum(trans_matrix, axis=1))\n",
    " \n",
    "\n",
    "# \n",
    "def confidence_model(sequence, probab_matrix, CHARS = CHARS):\n",
    "        #log likelihood\n",
    "        log_prob = np.sum([np.log1p(probab_matrix[CHARS.index(first), \n",
    "                                                CHARS.index(second)])\n",
    "                           for first, second in zip(sequence, sequence[1:])])\n",
    "\n",
    "        return log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for p in train_A:\n",
    "    with open(p) as f:\n",
    "        sequence = f.read()\n",
    "        probab_matrix_A= fit_model(sequence, probab_matrix_A, trans_matrix_A)\n",
    "\n",
    "\n",
    "for p in train_B:\n",
    "    with open(p) as f:\n",
    "        sequence = f.read()\n",
    "        probab_matrix_B= fit_model(sequence, probab_matrix_B, trans_matrix_B)\n",
    "        \n",
    "for p in train_C:\n",
    "    with open(p) as f:\n",
    "        sequence = f.read()\n",
    "        probab_matrix_C= fit_model(sequence, probab_matrix_C, trans_matrix_C)\n",
    "        \n",
    "        \n",
    "# print (probab_matrix_A)\n",
    "# print (probab_matrix_B)\n",
    "# print (probab_matrix_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probab(sequence, probab_matrixes = [probab_matrix_A, probab_matrix_B, probab_matrix_C] ):\n",
    "    \n",
    "    likelihood = np.array([confidence_model(sequence, probab_matrix) for probab_matrix in probab_matrixes]) * prior\n",
    "#     print (likelihood)\n",
    "#     print (np.sum(likelihood))\n",
    "    return likelihood / np.sum(likelihood)\n",
    "            \n",
    "def predict_lang(sequence, LANGS= LANGS):\n",
    "    lang_prob = predict_probab(sequence)\n",
    "#     print (lang_prob)\n",
    "    return LANGS[np.argmax(lang_prob)]\n",
    "    \n",
    "def confidence(sequence):\n",
    "    return np.max(predict_probab(sequence))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "[0.28728075 0.56292148 0.14979776]\n",
      "0.5629214814395022\n",
      "\n",
      "A\n",
      "[0.53336556 0.25270946 0.21392498]\n",
      "0.533365557565735\n",
      "\n",
      "A\n",
      "[0.50524363 0.23734176 0.25741461]\n",
      "0.5052436301033839\n",
      "\n",
      "A\n",
      "[0.47214125 0.25503971 0.27281903]\n",
      "0.47214125185327466\n",
      "\n",
      "A\n",
      "[0.46269974 0.33464608 0.20265418]\n",
      "0.4626997411516312\n",
      "\n",
      "C\n",
      "[0.20737789 0.13968117 0.65294094]\n",
      "0.6529409446734137\n",
      "\n",
      "A\n",
      "[0.51415268 0.27934916 0.20649816]\n",
      "0.514152676969759\n",
      "\n",
      "C\n",
      "[0.14789615 0.17909483 0.67300902]\n",
      "0.6730090213000319\n",
      "\n",
      "C\n",
      "[0.19774337 0.15432402 0.64793262]\n",
      "0.6479326164236276\n",
      "\n",
      "B\n",
      "[0.23501763 0.60802956 0.15695281]\n",
      "0.6080295578994104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in test:\n",
    "    with open(p) as f:\n",
    "        test_sequence = f.read()\n",
    "#         print ()\n",
    "#         print (test_sequence)\n",
    "        print (predict_lang(test_sequence))\n",
    "        print (predict_probab(test_sequence))\n",
    "        print (confidence(test_sequence))\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
